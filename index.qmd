---
title: "3-in-1-Workshop"
subtitle: "Einführung in Korrelation, Regression und Multilevel-Analyse mit R"
format: html
lang: de
date: today
license: "CC BY-SA"
html-table-processing: none
link-external-newwindow: true
toc: true
toc-location: body
embed-resources: false
theme: minty
title-block-banner: true
published-title: Letzte Aktualisierung
page-layout: full
code-link: true
execute: 
  warning: false
  message: false
author:
  name: Pawel R. Kulawiak
  orcid: 0000-0001-5939-4380
  email: kulawiak.pawel@uni-koeln.de
  url: https://pawelkulawiak.github.io/
  affiliations:
    name: Universität zu Köln, Graduiertenschule für Lehrer:innenbildung
    url: https://zfl.uni-koeln.de/graduiertenschule/die-graduiertenschule-auf-einen-blick/team
---

```{=html}
<style>
/* Add R logo to the title banner */
#title-block-header.quarto-title-block.default .quarto-title::before {
  content: '';
  display: block;
  background-image: url('https://www.r-project.org/Rlogo.png');
  background-size: contain;
  background-repeat: no-repeat;
  background-position: left;
  width: 100%;
  height: 100px;
  margin-bottom: 20px;
}
</style>
```

## Motivation

:::::: {.grid}

::: {.g-col-5}
![[Bickel, R. (2007). Multilevel analysis for applied research: It's just regression! The Guilford Press.](https://psycnet.apa.org/record/2007-06641-000)](https://m.media-amazon.com/images/I/417C8lvO3eL.jpg)
:::

::: {.g-col-7}
> Multilevel
analysis has dramatically burst on the scene, and we now have the statistical tools to
study phenomena at multiple levels. However, many researchers think that they cannot
conduct such analyses because they are too complicated and they require specialized,
expensive software. Fortunately, as this book shows, both of these beliefs are mistaken.

> First, multilevel analysis is not all that complex, as conveyed in the subtitle of the
book: **“It’s Just Regression.”** If the reader understands multiple regression, the fundamental statistical model in the social sciences, it is a relatively simple step to learn about
multilevel analysis.

Series Editor’s Note (David A. Kenny)

::: {.callout-tip}
## Ablauf
**Korrelation → Regression → Multilevel-Analysis (Multilevel-Regression)**
:::

:::

::::::

## Pakete

```{r}
library(tidyverse)   # https://www.tidyverse.org/
library(readxl)      # https://readxl.tidyverse.org/ (Teil von tidyverse)
library(haven)       # https://haven.tidyverse.org/ (Teil von tidyverse)
library(gt)          # https://gt.rstudio.com/
library(ggside)      # https://cran.r-project.org/web/packages/ggside/readme/README.html
library(see)         # https://easystats.github.io/see/
library(correlation) # https://easystats.github.io/correlation/index.html
library(sjPlot)      # https://strengejacke.github.io/sjPlot/
library(lme4)        # https://cran.r-project.org/web/packages/lme4/index.html
```

```{r}
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(readxl)) install.packages("readxl")
if (!require(haven)) install.packages("haven")
if (!require(gt)) install.packages("gt")
if (!require(ggside)) install.packages("ggside")
if (!require(see)) install.packages("see")
if (!require(correlation)) install.packages("correlation")
if (!require(sjPlot)) install.packages("sjPlot")
if (!require(lme4)) install.packages("lme4")
```

## Korrelation

::::::: callout-tip
## Datenquelle

Imuta K, Scarf D, Pharo H, Hayne H (2013) Drawing a Close to the Use of Human Figure Drawings as a Projective Measure of Intelligence. PLoS ONE 8(3): e58991.

- <https://doi.org/10.1371/journal.pone.0058991> (Paper)
- <https://doi.org/10.1371/journal.pone.0058991.s001> (Daten im Word-Format)
- <https://github.com/PawelKulawiak/rworkshop/blob/main/DATA_doi_10.1371_journal.pone.0058991.xlsx> (Daten im Excel-Format)
- <https://github.com/PawelKulawiak/rworkshop/raw/refs/heads/main/DATA_doi_10.1371_journal.pone.0058991.xlsx> (Direkter Download: Daten im Excel-Format)

Variablen:

-   **DAP_IQ**: [Draw-A-Person Intellectual Ability Test](https://en.wikipedia.org/wiki/Draw-a-Person_test) ([Mann-Zeichen-Test](https://www.testzentrale.de/shop/der-mann-zeichen-test.html))
-   **WPPSI**: [Wechsler Preschool and Primary Scale of Intelligence](https://de.wikipedia.org/wiki/Wechsler_Preschool_and_Primary_Scale_of_Intelligence)

\

:::::: grid
::: g-col-4
![](https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0058991.g003&type=large)
:::

::: g-col-3
![](https://www.testzentrale.de/shop/media/catalog/product/cache/1600x/17f82f742ffe127f42dca9de82fb58b1/4/7/4700801.jpg)
:::

::: g-col-3
![](https://www.testzentrale.de/shop/media/catalog/product/cache/1600x/17f82f742ffe127f42dca9de82fb58b1/2/8/2813001.jpg)
:::
::::::
:::::::

```{r}
DATA <-
  read_xlsx("DATA_doi_10.1371_journal.pone.0058991.xlsx")

head(DATA) %>%
  gt() %>%
  tab_options(table.align = "left") %>%
  tab_header("Die ersten 6 kinder des Datensatzes", "100 Kinder insgesamt")
```

### Visualisierung

::: {.callout-tip}
## Univariat und bivariat
Die dargestellten Abbildungen demonstrieren die univariate Visualisierung beider Verteilungen (separate Histogramme für DAP_IQ und WPPSI) und anschließend die Überführung der beiden univariaten Verteilungen in einen 2-dimensionalen Raum (2-dimensionale Ebene; x und y), also das bivariate Streudiagramm (scatter plot) der beiden Variablen (DAP_IQ und WPPSI).
:::

```{=html}
<iframe src="visualisierung.html" width="100%" height="700px" frameborder="0"></iframe>
```

:::::: {.grid}

::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_point(aes(y = 0), col = "blue") +
  geom_point(aes(x = 0), col = "blue") +
  xlim(c(0, 150)) +
  ylim(c(0, 140)) +
  theme_classic(base_size = 12)
```
:::

::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  #
  #
  xlim(c(0, 150)) +
  ylim(c(0, 140)) +
  theme_classic(base_size = 12)
```
:::
::::::

:::::: {.grid}

::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) +
  geom_point(col = "blue") +
  geom_point(aes(y = 0), col = "blue") +
  geom_point(aes(x = 0), col = "blue") +
  xlim(c(0, 150)) +
  ylim(c(0, 140)) +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 12) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) 
```
:::

::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  #
  #
  xlim(c(0, 150)) +
  ylim(c(0, 140)) +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 12) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) 
```
:::
::::::



:::::: {.grid}

::: {.g-col-6}
![<https://commons.wikimedia.org/wiki/File:MultivariateNormal.png> by Bscan](https://upload.wikimedia.org/wikipedia/commons/8/8e/MultivariateNormal.png)
:::

::: {.g-col-6}
![<https://commons.wikimedia.org/wiki/File:Multivariate_normal_density.png> by JonskiC](https://upload.wikimedia.org/wikipedia/commons/5/59/Multivariate_normal_density.png)
:::
::::::

```{r}
DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 12) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) 
```

::: {.callout-tip}
## Übung
**Interpretieren und beschreiben Sie die unterschiedlichen Punktewolken.**
:::

```{r}
#| echo: false
#| out-width: "100%"
#| fig-height: 9
library(faux)
library(patchwork)

P_1 <-
  DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Original Data")

set.seed(1988)
DAT <- rnorm_multi(n = 100, 
                  mu = c(100, 100),
                  sd = c(15, 10),
                  r = c(0), 
                  varnames = c("DAP_IQ", "WPPSI"),
                  empirical = FALSE) %>% round()

P_2 <-
  DAT %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Simulated Data A")

set.seed(1988)
DAT <- rnorm_multi(n = 100, 
                  mu = c(100, 100),
                  sd = c(15, 10),
                  r = c(0.6), 
                  varnames = c("DAP_IQ", "WPPSI"),
                  empirical = FALSE) %>% round()

P_3 <-
  DAT %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Simulated Data B")

set.seed(1988)
DAT <- rnorm_multi(n = 100, 
                  mu = c(100, 100),
                  sd = c(15, 10),
                  r = c(0.8), 
                  varnames = c("DAP_IQ", "WPPSI"),
                  empirical = FALSE) %>% round()

P_4 <-
  DAT %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Simulated Data C")

set.seed(1988)
DAT <- rnorm_multi(n = 100, 
                  mu = c(100, 100),
                  sd = c(15, 10),
                  r = c(-0.6), 
                  varnames = c("DAP_IQ", "WPPSI"),
                  empirical = FALSE) %>% round()

P_5 <-
  DAT %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Simulated Data D")

set.seed(1988)
DAT <- rnorm_multi(n = 100, 
                  mu = c(100, 100),
                  sd = c(15, 10),
                  r = c(-0.8), 
                  varnames = c("DAP_IQ", "WPPSI"),
                  empirical = FALSE) %>% round()

P_6 <-
  DAT %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Simulated Data E")

(P_1 | P_2) / (P_3 | P_4) / (P_5 | P_6)
```

::: {.callout-tip collapse="true"}
## Lösung

```{r}
#| echo: false
#| out-width: "100%"
#| fig-height: 9

P_1 <-
  DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Original Data",
       title = paste0("r = ", cor(DATA$DAP_IQ, DATA$WPPSI) %>% round(2)))

set.seed(1988)
DAT <- rnorm_multi(n = 100, 
                  mu = c(100, 100),
                  sd = c(15, 10),
                  r = c(0), 
                  varnames = c("DAP_IQ", "WPPSI"),
                  empirical = FALSE) %>% round()

P_2 <-
  DAT %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Simulated Data A",
       title = paste0("r = ", cor(DAT$DAP_IQ, DAT$WPPSI) %>% round(2)))

set.seed(1988)
DAT <- rnorm_multi(n = 100, 
                  mu = c(100, 100),
                  sd = c(15, 10),
                  r = c(0.6), 
                  varnames = c("DAP_IQ", "WPPSI"),
                  empirical = FALSE) %>% round()

P_3 <-
  DAT %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Simulated Data B",
       title = paste0("r = ", cor(DAT$DAP_IQ, DAT$WPPSI) %>% round(2)))

set.seed(1988)
DAT <- rnorm_multi(n = 100, 
                  mu = c(100, 100),
                  sd = c(15, 10),
                  r = c(0.8), 
                  varnames = c("DAP_IQ", "WPPSI"),
                  empirical = FALSE) %>% round()

P_4 <-
  DAT %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Simulated Data C",
       title = paste0("r = ", cor(DAT$DAP_IQ, DAT$WPPSI) %>% round(2)))

set.seed(1988)
DAT <- rnorm_multi(n = 100, 
                  mu = c(100, 100),
                  sd = c(15, 10),
                  r = c(-0.6), 
                  varnames = c("DAP_IQ", "WPPSI"),
                  empirical = FALSE) %>% round()

P_5 <-
  DAT %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Simulated Data D",
       title = paste0("r = ", cor(DAT$DAP_IQ, DAT$WPPSI) %>% round(2)))

set.seed(1988)
DAT <- rnorm_multi(n = 100, 
                  mu = c(100, 100),
                  sd = c(15, 10),
                  r = c(-0.8), 
                  varnames = c("DAP_IQ", "WPPSI"),
                  empirical = FALSE) %>% round()

P_6 <-
  DAT %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) + 
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 10) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) +
  labs(subtitle = "Simulated Data E",
       title = paste0("r = ", cor(DAT$DAP_IQ, DAT$WPPSI) %>% round(2)))

(P_1 | P_2) / (P_3 | P_4) / (P_5 | P_6)
```
---

**Produkt-Moment-Korrelation (*r*) [Bravais-Pearson correlation, Pearson correlation]**

> Nach Cohen (1988) kann *r* als Effektgröße des Zusammenhangs verwendet werden:

> - |*r*| ≈ .1 «schwach»
> - |*r*| ≈ .3 «mittel»
> - |*r*| ≈ .5 «stark»

Quelle: <https://dorsch.hogrefe.com/stichwort/produkt-moment-korrelation>

---

![<https://commons.wikimedia.org/wiki/File:Correlation_examples2.svg> by DenisBoigelot](https://upload.wikimedia.org/wikipedia/commons/d/d4/Correlation_examples2.svg){width=100%}
---

**Interaktives Tool**

<https://rpsychologist.com/correlation/>

---

**Anscombe's quartet**

Anscombe, F. J. (1973). Graphs in Statistical Analysis. The American Statistician, 27(1), 17–21. <https://doi.org/10.1080/00031305.1973.10478966>

> Das Anscombe-Quartett besteht aus vier Mengen von Datenpunkten, die nahezu identische einfache statistische Eigenschaften haben, aber aufgetragen sehr verschieden aussehen. Jede dieser vier Mengen besteht aus elf (x,y)-Punkten. Diese vier Mengen wurden im Jahre 1973 von dem englischen Statistiker Francis Anscombe konstruiert, um die Bedeutung einer graphischen Datenanalyse herauszustellen und die Effekte von Ausreißern zu demonstrieren.

Quelle: <https://de.wikipedia.org/wiki/Anscombe-Quartett>

![<https://en.wikipedia.org/wiki/File:Anscombe%27s_quartet_3.svg> by Schutz](https://upload.wikimedia.org/wikipedia/commons/e/ec/Anscombe%27s_quartet_3.svg)
:::

::: {.callout-tip}
## Übung
**Replikation:**

Visualisieren Sie den Zusammenhang zwischen DAP_IQ und WPPSI (**Streudiagramm mit Histogrammen**).

---

**Übung mit neuen Daten:**

Gibt es einen Zusammenhang zwischen Anzahl der Freunde in der Schule und Gefühlen der Einsamkeit in der Schule?

Visualisieren Sie den Zusammenhang (**Streudiagramm mit Histogrammen**).

Die Daten finden Sie im Paper:

Vyrastekova, J. (2021). Social inclusion of students with special educational needs assessed by the Inclusion of Other in the Self scale. PLOS ONE, 16(4), e0250070. <https://doi.org/10.1371/journal.pone.0250070>

Direkter Download der Daten: 

<https://doi.org/10.1371/journal.pone.0250070.s003>

Direkter Import der Daten:

```{r}
DATA <-
  read_sav("https://doi.org/10.1371/journal.pone.0250070.s003")
```
:::

::: {.callout-tip collapse="true"}
## Lösung
```{r}
DATA %>%
  ggplot(aes(x = FriendsAtSchool, y = LonelinessSchool)) +
  geom_point(col = "blue") +
  geom_xsidedensity(col = "blue", fill = "lightgray") +
  geom_ysidedensity(col = "blue", fill = "lightgray") +
  theme_classic(base_size = 12) +
  theme(ggside.panel.scale.x = 0.2,
        ggside.panel.scale.y = 0.2,
        ggside.axis.text = element_blank(),      
        ggside.axis.ticks = element_blank(),
        ggside.axis.line = element_blank()) 
```
:::

### Berechnung

```{r}
#| echo: false
DATA <- read_xlsx("DATA_doi_10.1371_journal.pone.0058991.xlsx")
```


```{r}
cor.test(DATA$DAP_IQ, DATA$WPPSI, alternative = "greater")

DATA %>%
  cor_test("DAP_IQ", "WPPSI", alternative = "greater")

DATA %>%
  cor_test("DAP_IQ", "WPPSI", alternative = "greater") %>%
  gt() %>% 
  tab_options(table.align = "left") %>% 
  fmt_number(decimals = 3) %>%
  tab_header("Correlation", "Draw-A-Person Intellectual Ability Test & Wechsler Preschool and Primary Scale of Intelligence")

DATA %>%
  cor_test("DAP_IQ", "WPPSI", alternative = "greater") %>%
  plot()
```

::: {.callout-tip}
## Übung
Berechnen und visualisieren Sie den Zusammenhang zwischen Anzahl der Freunde in der Schule und Gefühlen der Einsamkeit in der Schule.

**In der Visualisierung soll der nummerische Wert der Korrelation dargestellt sein.**

a)	Analyse mit gesamten Datensatz
b)	Analyse ohne Ausreißer (Ausreißer entfernen)
:::

::: {.callout-tip collapse="true"}
## Lösung
```{r}
DATA <-
  read_sav("https://doi.org/10.1371/journal.pone.0250070.s003")

DATA %>% 
  cor_test("FriendsAtSchool", "LonelinessSchool") %>%
  gt() %>% 
  tab_options(table.align = "left") %>% 
  fmt_number(decimals = 3)
```
:::::: {.grid}

::: {.g-col-6}
```{r}
DATA %>%
  #
  cor_test("FriendsAtSchool", "LonelinessSchool") %>%
  plot() +
  #
  labs(title = "Analyse mit gesamten Datensatz") +
  theme_classic(base_size = 14)
```
:::

::: {.g-col-6}
```{r}
DATA %>%
  filter(FriendsAtSchool < 30) %>% 
  cor_test("FriendsAtSchool", "LonelinessSchool") %>%
  plot() +
  xlim(c(0, 30)) +
  labs(title = "Analyse ohne Ausreißer") +
  theme_classic(base_size = 14)
```
:::
::::::
:::

### Punktbiseriale Korrelation

:::::: {.grid}

::: {.g-col-6}

```{r}
#| echo: false
# Create binary x variable
n <- 100  # total sample size
x <- c(rep(0, n/2), rep(1, n/2))  # equal groups

# Create metric y variable
# Group 0: mean = 30, sd = 5
# Group 1: mean = 50, sd = 5
# Mean difference = 50 - 30 = 20
set.seed(1988)
y <- ifelse(x == 0, 
            rnorm(n/2, mean = 30 + 10, sd = 8),  # Group 0
            rnorm(n/2, mean = 60 + 10, sd = 8))  # Group 1

# Create dataframe
DAT <- data.frame(x = x, y = y)

DAT %>%
  cor_test("x", "y") %>%
  plot() +
  ylim(c(0,100)) +
  theme_classic(base_size = 16)

```
:::

::: {.g-col-6}

\ 

> Parametrisches Verfahren zur Bestimmung des Ausmaßes des Zusammenhangs (Korrelation) zwischen einer intervallskalierten Variable und einer dichotomen Variable.

> Die punktbiseriale Korrelation und der t-Test für unabhängige Stichproben sind insofern äquivalente Verfahren, als die Ergebnisse direkt ineinander überführt werden können und der p-Wert (Signifikanztest) für beide Verfahren identisch ist. 

Quelle: <https://dorsch.hogrefe.com/stichwort/punktbiseriale-korrelation>

:::
::::::

:::::: {.grid}

::: {.g-col-6}
```{r}
#| code-fold: true
DATA %>%
  filter(FriendsAtSchool < 30) %>%
  cor_test("h_psycho", "FriendsAtSchool") %>%
  plot() +
  theme_classic(base_size = 16)
```
:::

::: {.g-col-6}
```{r}
#| code-fold: true
DATA %>%
  filter(FriendsAtSchool < 30) %>%
  ggplot(aes(x = as_factor(h_psycho), y = FriendsAtSchool)) +
  geom_boxplot(fill = "lightgray") +
  geom_jitter(width = 0.1,
              height = 0,
              shape = 21,
              alpha = 0.2,
              size = 4,
              fill = "blue") +
  stat_summary(fun = mean, 
               geom = "line", 
               aes(group = "x"), 
               color = "blue", 
               linewidth = 1) +
  theme_classic(base_size = 16)
```
:::
::::::

:::::: {.grid}

::: {.g-col-6}
:::

::: {.g-col-6}
```{r}
#| code-fold: true
DATA %>%
  filter(FriendsAtSchool < 30) %>%
  ggplot(aes(x = as_factor(h_psycho), y = FriendsAtSchool)) +
  geom_violin(fill = "lightgray") +
  geom_jitter(width = 0.1,
              height = 0,
              shape = 21,
              alpha = 0.2,
              size = 4,
              fill = "blue") +
  stat_summary(fun = mean, 
               geom = "line", 
               aes(group = "x"), 
               color = "blue", 
               linewidth = 1) +
  theme_classic(base_size = 16)
```
:::
::::::

### Korrelationsmatrix

```{r}
#| fig-width: 8
#| fig-height: 8
#| code-fold: true
library(GGally) # https://ggobi.github.io/ggally/reference/ggpairs.html
DATA %>% 
  select(LonelinessHome,
         LonelinessSchool,
         SchoolInclusion,
         ParentalInclusion,
         FriendsNotAtSchool,
         FriendsAtSchool) %>%
  ggpairs()
```

```{r}
#| fig-width: 10
#| fig-height: 7
#| code-fold: true
# https://easystats.github.io/see/articles/correlation.html
DATA %>% 
  select(LonelinessHome,
         LonelinessSchool,
         SchoolInclusion,
         ParentalInclusion,
         FriendsNotAtSchool,
         FriendsAtSchool) %>%
  correlation(p_adjust = "none") %>%
  summary(redundant = TRUE) %>% 
  plot()
```


::: {.callout-tip}
## Weiterführende Informationen

- <https://openintro-ims.netlify.app/model-slr> (Lehrbuch)
- <https://moderndive.com/v2/regression.html> (Lehrbuch)
- <https://r-charts.com/correlation/>
- <https://r-graph-gallery.com/correlogram.html>
- <https://r-graph-gallery.com/scatterplot.html>
- <https://easystats.github.io/correlation/>
- <https://easystats.github.io/see/>
- <https://corrr.tidymodels.org/>
:::

## Regression

### Visualisierung

```{r}
DATA <-
  read_xlsx("DATA_doi_10.1371_journal.pone.0058991.xlsx")

DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) +
  geom_point() +
  geom_smooth() + # glatt (LOESS: locally estimated scatterplot smoothing)
  theme_classic()

DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  theme_classic()

DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic()

DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  xlim(c(0, 150)) +
  ylim(c(0, 140)) +
  theme_classic()

DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE) +
  xlim(c(0, 150)) +
  ylim(c(0, 140)) +
  theme_classic()
```

### Berechnung

- <https://de.wikipedia.org/wiki/Lineare_Regression>
- <https://www.theanalysisfactor.com/the-many-names-of-independent-variables/>

*y* = *b*~0~ + *b*~1~*x*~1~

y = n + mx

f(x) = n + mx

y = intercept + x

y = x

AV = UV 

Outcome = Prädiktor

Outcome ~ Prädiktor

y ~ x

```{r}
lm(WPPSI ~ DAP_IQ, data = DATA)
```

y = n + mx

f(x) = n + mx

y = intercept + x

y = 79.39 + 0.23x

WPPSI = 79.39 + 0.23*DAP_IQ

```{r}
lm(WPPSI ~ DAP_IQ, data = DATA) %>%
  summary()
```

---

:::::: {.grid}

::: {.g-col-5}
```{r}
lm(WPPSI ~ DAP_IQ, data = DATA) %>%
  tab_model()
```

::: {.callout-tip}
## Übung
Interpretieren Sie die folgenden Parameter der Regressionsanalyse unter Berücksichtigung der Visualisierung (Streudiagramm mit Regressionsgerade):

- Intercept
- Regressionskoeffizient für DAP_IQ
- *R*^2^
:::

:::

::: {.g-col-7}
```{r}
#| code-fold: true
DATA %>%
  ggplot(aes(x = DAP_IQ, y = WPPSI)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE) +
  xlim(c(0, 150)) +
  ylim(c(0, 140)) +
  theme_classic()
```
:::
::::::

::: {.callout-tip}
## Übung
Rechnen Sie 2 separate Regressionsmodelle und visualisieren Sie die Zusammenhänge mit Regressionsgeraden.

**Regressionsmodell A**: Gibt es einen Zusammenhang zwischen Anzahl der Freunde in der Schule und Gefühlen der Einsamkeit in der Schule?

**Regressionsmodell B**: Gibt es einen Zusammenhang zwischen psychischer Auffälligkeit und Gefühlen der Einsamkeit in der Schule?

**Ausreißer bitte vor den Analysen entfernen (!):**

```{r}
DATA <-
  read_sav("https://doi.org/10.1371/journal.pone.0250070.s003") %>% 
  filter(FriendsAtSchool < 30)
```
:::

::: {.callout-tip collapse="true"}
## Lösung

:::::: {.grid}
::: {.g-col-5}
```{r}
lm(LonelinessSchool ~ FriendsAtSchool, data = DATA) %>% 
  tab_model()
```
:::
::: {.g-col-7}
```{r}
#| code-fold: true
DATA %>%
  ggplot(aes(x = FriendsAtSchool, y = LonelinessSchool)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE) +
  theme_classic()
```
:::
:::::

:::::: {.grid}
::: {.g-col-5}
```{r}
lm(LonelinessSchool ~ h_psycho, data = DATA) %>% 
  tab_model()
```
:::
::: {.g-col-7}
```{r}
#| code-fold: true
DATA %>%
  ggplot(aes(x = h_psycho, y = LonelinessSchool)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE) +
  theme_classic()

DATA %>%
  ggplot(aes(x = as_factor(h_psycho), y = LonelinessSchool)) +
  geom_violin(fill = "lightgray") +
  geom_jitter(width = 0.1,
              height = 0,
              shape = 21,
              alpha = 0.2,
              size = 4,
              fill = "blue") +
  stat_summary(fun = mean, 
               geom = "line", 
               aes(group = "x"), 
               color = "blue", 
               linewidth = 1) +
               theme_classic()
```
:::
:::::
:::

### Multiple Regression (mit Interaktionseffekt)
:::::: {.grid}
::: {.g-col-6}
```{r}
lm(LonelinessSchool ~ Female + FriendsAtSchool, data = DATA) %>% 
  tab_model()
```
:::
::: {.g-col-6}
```{r}
lm(LonelinessSchool ~ Female * FriendsAtSchool, data = DATA) %>% 
  tab_model()
```
:::
::::::

---

:::::: {.grid}
::: {.g-col-5}
```{r}
lm(LonelinessSchool ~ Female * FriendsAtSchool, data = DATA) %>% 
  tab_model()
```
:::
::: {.g-col-7}
```{r}
#| code-fold: true
DATA %>%
  filter(FriendsAtSchool < 30) %>% 
  ggplot(aes(x = FriendsAtSchool, y = LonelinessSchool, color = as_factor(Female))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic()
```
:::
::::::

::: {.callout-tip}
## Übung
Rechnen Sie Regressionsmodelle mit Interaktionen:

**Regressionsmodell A**:  Vorhersage von Gefühlen der Einsamkeit in der Schule anhand psychischer Auffälligkeit und Anzahl der Freunde in der Schule.

**Regressionsmodell B**:  Vorhersage von Gefühlen der Einsamkeit in der Schule anhand motorischer Auffälligkeit und Anzahl der Freunde in der Schule.


**Ausreißer bitte vor den Analysen entfernen (!):**

```{r}
DATA <-
  read_sav("https://doi.org/10.1371/journal.pone.0250070.s003") %>% 
  filter(FriendsAtSchool < 30)
```
:::

::: {.callout-tip collapse="true"}
## Lösung

:::::: {.grid}
::: {.g-col-5}
```{r}
lm(LonelinessSchool ~ h_psycho * FriendsAtSchool, data = DATA) %>% 
  tab_model()
```
:::
::: {.g-col-7}
```{r}
#| code-fold: true
DATA %>%
  filter(FriendsAtSchool < 30) %>% 
  ggplot(aes(x = FriendsAtSchool, y = LonelinessSchool, color = as_factor(h_psycho))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic()
```
:::
::::::

---

:::::: {.grid}
::: {.g-col-5}
```{r}
lm(LonelinessSchool ~ h_motor * FriendsAtSchool, data = DATA) %>% 
  tab_model()
```
:::
::: {.g-col-7}
```{r}
#| code-fold: true
DATA %>%
  filter(FriendsAtSchool < 30) %>% 
  ggplot(aes(x = FriendsAtSchool, y = LonelinessSchool, color = as_factor(h_motor))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic()
```
:::
::::::
:::

::: {.callout-tip}
## Weiterführende Informationen

- <https://openintro-ims.netlify.app/model-slr> (Lehrbuch)
- <https://openintro-ims.netlify.app/model-mlr> (Lehrbuch)
- <https://moderndive.com/v2/regression.html> (Lehrbuch)
- <https://moderndive.com/v2/multiple-regression.html> (Lehrbuch)
:::

## Multilevel-Regression

:::::: {.grid}
::: {.g-col-6}
![](FUN.png)
:::
::: {.g-col-6}
- <https://www.theanalysisfactor.com/many-names-multilevel-models/>
- [Mehrebenenanalyse](https://dorsch.hogrefe.com/stichwort/mehrebenenanalyse)
- Hierarchische Lineare Modellierung
- Gemischte lineare Regression
- Multilevel-Analyse
- Multilevel model
- hierarchical linear model
- linear mixed-effect model
- mixed model
- nested data model
- random coefficient model
- random-effects model
- random parameter model
- Fixed and random effects model

- **It's Just Regression**

:::
::::::

```{r}
DATA <- read_excel("simulated_multi_level_data_ri.xlsx")

DATA %>% 
  select(id, social_inclusion, team_sports_activities) %>%
  head()  %>%
  gt() %>%
  tab_options(table.align = "left") %>%
  tab_header("Die ersten 6 kinder des Datensatzes", "360 Kinder insgesamt")
```



:::::: {.grid}
::: {.g-col-5}
```{r}
lm(social_inclusion ~ team_sports_activities, data = DATA) %>% 
  tab_model()
```
:::

::: {.g-col-7}
```{r}
DATA %>%
  ggplot(aes(x = team_sports_activities, y = social_inclusion)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic()
```
:::
::::::


::: {.callout-tip collapse="true"}
## Mehrebenen-Datenstruktur (nested data, clustered data)
![](nested.gif){width="100%"}

![](nested.png){width="100%"}
:::

---

```{=html}
<iframe src="slides.html" width="100%" height="700px" frameborder="0"></iframe>
```

### Mixed Effects Model: Random Intercept Model

:::::: {.grid}
::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = team_sports_activities, y = social_inclusion)) + ###########
  geom_point() +
  #
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic(base_size = 14)

lm(social_inclusion ~ team_sports_activities, data = DATA) %>% ##########
  tab_model()
```
:::


::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = team_sports_activities, y = social_inclusion, color = CLASS)) +
  geom_point() +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic(base_size = 14)

lmer(social_inclusion ~ team_sports_activities + (1 | CLASS), data = DATA) %>% 
  tab_model()
```
**In einer durchschnittlichen Klasse: Wenn team_sports_activities = 0, dann erwarten wir eine social_inclusion von 8.10**
:::
::::::

---

:::::: {.grid}
::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = team_sports_activities, y = social_inclusion, color = CLASS)) +
  geom_point() +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic(base_size = 14)

lmer(social_inclusion ~ team_sports_activities + (1 | CLASS), data = DATA) %>% 
  tab_model()
```
**In einer durchschnittlichen Klasse: Wenn team_sports_activities = 0, dann erwarten wir eine social_inclusion von 8.10**
:::


::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = team_sports_activities %>% scale(scale = F), y = social_inclusion, color = CLASS)) +
  geom_point() +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic(base_size = 14)

lmer(social_inclusion ~ team_sports_activities %>% scale(scale = F) + (1 | CLASS), data = DATA) %>% 
  tab_model()
```
**In einer durchschnittlichen Klasse: Wenn team_sports_activities durchschnittlich ist (= 0), dann erwarten wir eine social_inclusion von 12.83**
:::
::::::

---


:::::: {.grid}
::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = team_sports_activities, y = social_inclusion, color = CLASS)) +
  geom_point() +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE, fullrange = T) +
  geom_vline(xintercept = 0) +
  theme_classic(base_size = 14)

lmer(social_inclusion ~ team_sports_activities + (1 | CLASS), data = DATA) %>% 
  tab_model()
```
**In einer durchschnittlichen Klasse: Wenn team_sports_activities = 0, dann erwarten wir eine social_inclusion von 8.10**
:::


::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = team_sports_activities %>% scale(scale = F), y = social_inclusion, color = CLASS)) +
  geom_point() +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE, fullrange = T) +
  geom_vline(xintercept = 0) +
  theme_classic(base_size = 14)

lmer(social_inclusion ~ team_sports_activities %>% scale(scale = F) + (1 | CLASS), data = DATA) %>% 
  tab_model()
```
**In einer durchschnittlichen Klasse: Wenn team_sports_activities durchschnittlich ist (= 0), dann erwarten wir eine social_inclusion von 12.83**
:::
::::::

---

### Centering at the Grand Mean (CGM), Centering Within Cluster (CWC) & Cross-Level Interactions

```{r}
DATA <-
  DATA %>%
  group_by(CLASS) %>%
  mutate(team_sports_activities_cwc = team_sports_activities - mean(team_sports_activities, na.rm = TRUE)) %>%
  ungroup()

DATA %>%
  ggplot(aes(x = team_sports_activities_cwc, y = social_inclusion, color = CLASS)) +
  geom_point() +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE, fullrange = T) +
  geom_vline(xintercept = 0) +
  theme_classic(base_size = 14)

lmer(social_inclusion ~ team_sports_activities_cwc + (1 | CLASS), data = DATA) %>% 
  tab_model()
```

---

![[Cross-level interaction between teacher-reported structuredness and student-level academic self-concept predicting student-level enjoyment (Lazarides & Raufelder, 2020)](https://doi.org/10.1111/bjep.12352): „At low levels of teacher-reported cognitive activation, student-level mathematics self-concept at T1 was not significantly related to student-level mathematics enjoyment (–1SD; β = .13, SE = 0.08, p = .10). At high levels of teacher-reported cognitive activation, student-level mathematics self-concept at T1 was positively and significantly related to student-level mathematics enjoyment (+1SD; β = .38, SE = 0.09, p < .001).“](https://bpspsychub.onlinelibrary.wiley.com/cms/asset/d63be79b-1970-4a6c-bffc-69f004028c9d/bjep12352-fig-0002-m.jpg)

::: {.callout-tip}
## Literatur
- <https://www.learn-mlms.com/08-module-8.html#module-8> (Lehrbuch)
- Enders, C. K., & Tofighi, D. (2007). Centering predictor variables in cross-sectional multilevel models: A new look at an old issue. Psychological Methods, 12(2), 121–138. <https://psycnet.apa.org/doi/10.1037/1082-989X.12.2.121>
- Aguinis, H., Gottfredson, R. K., & Culpepper, S. A. (2013). Best-Practice Recommendations for Estimating Cross-Level Interaction Effects Using Multilevel Modeling. Journal of Management, 39(6), 1490–1528. <https://doi.org/10.1177/0149206313478188>
:::

{{< video https://www.youtube.com/embed/lTPLX6UovEk?si=YmyahmWmohMAc6bH >}}


::: {.callout-tip}
## Übung: Klassische Regression vs. Random Intercept Model
- **Klassische Regression:** Berechnen und visualisieren Sie den Zusammenhang zwischen Sport und sozialer Inklusion.
- **Random Intercept Model:** Berechnen und visualisieren Sie den Zusammenhang zwischen Sport und sozialer Inklusion unter Berücksichtigung der genesteten Datenstruktur (Kinder in Schulklassen).

Daten-Download: <https://github.com/PawelKulawiak/3in1/blob/main/simulated_multi_level_data_rs.xlsx>

```{r}
DATA <- read_excel("simulated_multi_level_data_rs.xlsx")
```
:::

::: {.callout-tip collapse="true"}
## Lösung

:::::: {.grid}
::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = team_sports_activities, y = social_inclusion)) + ###########
  geom_point() +
  #
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic(base_size = 14)

lm(social_inclusion ~ team_sports_activities, data = DATA) %>% ##########
  tab_model()
```
:::


::: {.g-col-6}
```{r}
DATA %>%
  ggplot(aes(x = team_sports_activities, y = social_inclusion, color = CLASS)) +
  geom_point() +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_classic(base_size = 14)

lmer(social_inclusion ~ team_sports_activities + (1 | CLASS), data = DATA) %>% 
  tab_model()
```
:::
::::::

:::

### Mixed Effects Model: Random Slope and Intercept Model

::: {.callout-tip collapse="true"}
## Lösung
```{r}

MOD_1 <- lmer(social_inclusion ~ team_sports_activities + (1 | CLASS), data = DATA) 
MOD_2 <- lmer(social_inclusion ~ team_sports_activities + (1 + team_sports_activities | CLASS), data = DATA)

tab_model(MOD_1, MOD_2, show.aic = T)
```
:::


::: {.callout-tip}
## Weiterführende Informationen

- <https://www.learn-mlms.com/> (Lehrbuch)
- <https://doi.org/10.4324/9781315650982> (Lehrbuch)
- <https://uk.sagepub.com/en-gb/eur/multilevel-analysis/book234191> (Lehrbuch)
- <https://www.bristol.ac.uk/cmm/learning/videos/>
- <https://www.rensvandeschoot.com/tutorials/lme4/>
:::

## R Session Info

```{r}
library(devtools)
session_info()
```

